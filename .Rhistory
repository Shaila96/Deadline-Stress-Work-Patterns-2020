###################################################
## Find out the ontologies
###################################################
ws_df <- get_ontologies(subj_name, day_serial, session_name, downsampled_pp_df)
# print(str(ws_df))
###################################################
## Find out the app monitor log
###################################################
ws_df <- get_app_usage_data(subj_name, day_serial, ws_df)
# print(str(ws_df))
# print(nrow(ws_df))
# print(levels(factor(ws_df$Application)))
## rbind.fill bind two data frames that don't have the same set of columns
full_day_df <- rbind.fill(rb_df, ws_df)
# print(levels(factor(full_day_df$Application)))
return(full_day_df)
}
merge_e4_data <- function(subj_name, day_serial, full_day_df) {
day_dir <- file.path(raw_data_dir, grp_dir, subj_name, day_serial)
## Two files for HR and EDA
# downsampled_e4_file_list <- get_matched_file_names(file.path(curated_data_dir, subj_data_dir), e4_file_pattern)
subj_day_info <- paste0('Group1_', subj_name, '_', day_serial, '_')
downsampled_e4_file_list <- get_matched_file_names(file.path(curated_data_dir, subj_data_dir), paste0(subj_day_info, 'HR', '|', subj_day_info, 'EDA'))
if(is_empty(downsampled_e4_file_list)) {
## Two files for HR and EDA
e4_file_list <- get_matched_file_names_recursively(day_dir, e4_file_pattern)
for(e4_file_name in e4_file_list) {
e4_df <- get_e4_data(day_dir, e4_file_name)
convert_to_csv(e4_df, file.path(curated_data_dir, subj_data_dir, paste0('Group1_', subj_name, '_', day_serial, '_', sub('.csv', '', sub('.*/', '', e4_file_name)), '.csv')))
##############################################################################################
full_day_df <- merge(full_day_df, e4_df, by='Timestamp', all=T)   ## CHECK!!! - all vs. all.x
##############################################################################################
}
} else {
for(e4_file_name in downsampled_e4_file_list) {
e4_df <- custom_read_csv(file.path(curated_data_dir, subj_data_dir, e4_file_name)) %>%
mutate(Timestamp=as.POSIXct(Timestamp))
# print(str(e4_df))
##############################################################################################
full_day_df <- merge(full_day_df, e4_df, by='Timestamp', all=T)   ## CHECK!!! - all vs. all.x
##############################################################################################
}
}
return(full_day_df)
}
merge_iwatch_data <- function(subj_name, day_serial, full_day_df) {
day_dir <- file.path(raw_data_dir, grp_dir, subj_name, day_serial)
iWatch_file_name <- get_matched_file_names_recursively(day_dir, iWatch_file_pattern)
if(!is_empty(iWatch_file_name)) {
full_day_df <- custom_read_csv(file.path(day_dir, iWatch_file_name)) %>%
rename(Timestamp=Time,
iWatch_HR=HeartRate) %>%
mutate(Timestamp=convert_s_interface_date(strptime(Timestamp, format='%Y-%m-%d %H:%M:%S')) - 5 * one_hour_sec) %>%
# mutate(Timestamp=Timestamp - 5 * one_hour_sec) %>%
##############################################################################################
merge(full_day_df, by='Timestamp', all=T) ## CHECK!!! - all vs. all.x
##############################################################################################
# print(str(full_day_df))
##############################################################################################
# full_day_df <- merge(full_day_df, iWatch_df, by='Timestamp', all=T)   ## CHECK!!! - all vs. all.x
##############################################################################################
}
return(full_day_df)
}
refactor_and_export_all_subj_data <- function(all_subj_df) {
#################################################################################
#################################################################################
# all_subj_df <- all_subj_df %>%
#   mutate(Ontologies=case_when(
#     is.na(Ontologies) & Treatment=='WS' & Participant_ID=='T001'~'Working',
#     is.na(Ontologies) & Treatment=='WS' & Participant_ID=='T003'~'C - Writing/Reading',
#     TRUE~Ontologies))
# all_subj_df <- all_subj_df %>%
#   mutate(Ontologies=case_when(
#   Ontologies==NA & Treatment=='WS' & Participant_ID=='T001'~'Working',
#   Ontologies==NA & Treatment=='WS' & Participant_ID=='T003'~'C - Writing/Reading'))
all_subj_df <- all_subj_df %>%
mutate(Ontologies=case_when(
#is.na(Ontologies) & Treatment=='WS' & Participant_ID=='T001'~'Working',
is.na(Ontologies) & Treatment=='WS' & Participant_ID=='T003'~'C - Writing/Reading',
TRUE~Ontologies))
# # # # This is for T001 & T003, for whom we only noted the break times
# # # all_subj_df[is.na(all_subj_df$Ontologies) & all_subj_df$Treatment=='WS' & all_subj_df$Participant_ID=='T001', ]$Ontologies <- 'Working'
# # # all_subj_df[is.na(all_subj_df$Ontologies) & all_subj_df$Treatment=='WS' & all_subj_df$Participant_ID=='T003', ]$Ontologies <- 'C - Writing/Reading'
#################################################################################
all_subj_df <- all_subj_df %>%
rename(Sinterface_Time=Time,
Activities=Ontologies,
Raw_PP=PP,
PP=NR_PP,
E4_HR=HR,
E4_EDA=EDA) %>%
## Calculating relative treatment time
group_by(Participant_ID, Day, Treatment) %>%
arrange(Timestamp) %>%
mutate(TreatmentTime=as.numeric(Timestamp)-as.numeric(head(Timestamp, 1))) %>%
select(Participant_ID,
Day,
Treatment,
Timestamp,
Sinterface_Time,
TreatmentTime,
Raw_PP,
PP,
E4_HR,
E4_EDA,
iWatch_HR,
Activities,
Application,
Application_QC1
) %>%
###################################################################################
## Note: This is very important to understand this code
## We were some missing WS data.
## So, we merge all data, and based on WS start and end time we get all WS data
## Here, we are removing NA Treatments - caused for merging all
drop_na(Treatment)
###################################################################################
# mean_df <- all_subj_df %>%
#   select(-Timestamp, -Sinterface_Time, -TreatmentTime, -Activities, -Application, -Application_QC1) %>%
#   group_by(Participant_ID, Day, Treatment) %>%
#   summarize_all(mean, na.rm=T) %>%
#   ungroup()
View(all_subj_df)
# write_log_msg(levels(factor(all_subj_df$Application)), curation_log_file)
write_log_msg(paste0('Total relative time mismatch row: ', nrow(all_subj_df[all_subj_df$Sinterface_Time != all_subj_df$TreatmentTime, ])), curation_log_file)
convert_to_csv(all_subj_df, file.path(curated_data_dir, physiological_data_dir, qc0_file_name))
# convert_to_csv(mean_df, file.path(curated_data_dir, physiological_data_dir, qc0_mean_file_name))
}
curate_data <- function() {
# subj_list <- get_dir_list(file.path(raw_data_dir, grp_dir))
subj_list <- custom_read_csv(file.path(curated_data_dir, utility_data_dir, subj_list_file_name))$Subject
sapply(subj_list, function(subj_name) {
# sapply(subj_list[5], function(subj_name) {
subj_dir <- file.path(raw_data_dir, grp_dir, subj_name)
day_list <- get_dir_list(subj_dir)
sapply(day_list, function(day_serial) {
# sapply(day_list[1], function(day_serial) {
tryCatch({
write_log_msg(paste0('\n----------\n', subj_name, '-', day_serial, "\n----------"), curation_log_file)
write_log_msg('Processing.....Resting Baseline', curation_log_file)
rb_df <- curate_rb_session_data(subj_name, day_serial)
write_log_msg('Processing.....Working Session', curation_log_file)
full_day_df <- curate_ws_session_data(subj_name, day_serial, rb_df)
write_log_msg('\nMerging.....e4 data', curation_log_file)
full_day_df <- merge_e4_data(subj_name, day_serial, full_day_df)
write_log_msg('Merging.....iwatch data', curation_log_file)
full_day_df <- merge_iwatch_data(subj_name, day_serial, full_day_df)
write_log_msg('Fixing.....missing working session data', curation_log_file)
## Here get the info from ws start and end time
## Check for the in this time period which rows has NA session
## Replace those treatements by ws
# full_day_df <-  add_missing_ws_session_data(subj_name, day_serial, full_day_df)
write_log_msg('Merging.....all subj data\n', curation_log_file)
all_subj_df <<- rbind.fill(all_subj_df, full_day_df)
},
error=function(err) {
write_log_msg(paste0('\n', decorator_hash, '\n', subj_name, '-', day_serial, ': ERROR!'), curation_log_file)
write_log_msg(paste0(err, decorator_hash), curation_log_file)
})
})
})
# convert_to_csv(win_app_usage_df, file.path(curated_data_dir, physiological_data_dir, 'win_app_usage_df.csv'))
# convert_to_csv(win_app_usage_df, file.path(curated_data_dir, physiological_data_dir, 'win_app_usage_row_num_df.csv'))
refactor_and_export_all_subj_data(all_subj_df)
}
#-------------------------#
#-------Main Program------#
#-------------------------#
curate_data()
#-------------------------#
#--------LIBRARIES--------#
#-------------------------#
library(dplyr)
library(stringr)    ## for func str_detect()
library(reshape2)
library(tidyr)
#-------------------------#
#-----GLOBAL VARIABLES----#
#-------------------------#
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
source(file.path(script_dir, 'us-common-functions.R'))
current_dir <- dirname(script_dir)
setwd(current_dir)
# activity_log_file <- file.path(log_dir, paste0('activity-log-', format(Sys.Date(), format='%m-%d-%y'), '.txt'))
# file.create(activity_log_file)
#-------------------------#
#---FUNCTION DEFINITION---#
#-------------------------#
get_final_activities <- function(all_subj_df) {
#all_subj_df <- all_subj_df %>% mutate(Activities_QC1=Activities) %>% ## @TANIM - CHANGE HERE!!!
all_subj_df <- all_subj_df %>%
mutate(Activities_QC1=Activities) %>% ## @TANIM - CHANGE HERE!!!
mutate(Activities_QC2=case_when(str_detect(Activities_QC1, computer_usage_pattern)~'Computer Working',
Treatment=='WS'~'Other Activities'))
all_subj_df$Activities1<-all_subj_df$Activities
all_subj_df<-all_subj_df %>%separate(Activities1, c("A", "B", "C"), ",")
all_subj_df$A<-trimws(all_subj_df$A)
all_subj_df$B<-trimws(all_subj_df$B)
if (is.na(all_subj_df$C)!=TRUE) {
all_subj_df$C<-trimws(all_subj_df$c)
}
#unique(all_subj_df$A)
all_subj_df$A<-gsub("\\(|\\)", "", all_subj_df$A)
all_subj_df$B<-gsub("\\(|\\)", "", all_subj_df$B)
all_subj_df$C<-gsub("\\(|\\)", "", all_subj_df$C)
all_subj_df$A<-case_when(str_detect(all_subj_df$A, Out)~"Out",
str_detect(all_subj_df$A, PW)~"PW",
str_detect(all_subj_df$A, PR)~"PR",
str_detect(all_subj_df$A, CW)~"CW",
str_detect(all_subj_df$A, CR)~"CR",
str_detect(all_subj_df$A, EiP)~"EiP",
str_detect(all_subj_df$A, OB)~"OB",
str_detect(all_subj_df$A, Working)~"Working",
str_detect(all_subj_df$A, Thinking)~"T",
str_detect(all_subj_df$A, SP)~"SP",
str_detect(all_subj_df$A, ELD)~"ELD",
str_detect(all_subj_df$A, PI)~"PI",
str_detect(all_subj_df$A, VI)~"VI"
)
all_subj_df$B<-case_when(str_detect(all_subj_df$B, Out)~"Out",
str_detect(all_subj_df$B, PW)~"PW",
str_detect(all_subj_df$B, PR)~"PR",
str_detect(all_subj_df$B, CW)~"CW",
str_detect(all_subj_df$B, CR)~"CR",
str_detect(all_subj_df$B, EiP)~"EiP",
str_detect(all_subj_df$B, OB)~"OB",
str_detect(all_subj_df$B, Working)~"Working",
str_detect(all_subj_df$B, Thinking)~"T",
str_detect(all_subj_df$B, SP)~"SP",
str_detect(all_subj_df$B, ELD)~"ELD",
str_detect(all_subj_df$B, PI)~"PI",
str_detect(all_subj_df$B, VI)~"VI"
)
all_subj_df$C<-case_when(str_detect(all_subj_df$C, Out)~"Out",
str_detect(all_subj_df$C, PW)~"PW",
str_detect(all_subj_df$C, PR)~"PR",
str_detect(all_subj_df$C, CW)~"CW",
str_detect(all_subj_df$C, CR)~"CR",
str_detect(all_subj_df$C, EiP)~"EiP",
str_detect(all_subj_df$C, OB)~"OB",
str_detect(all_subj_df$C, Working)~"Working",
str_detect(all_subj_df$C, Thinking)~"T",
str_detect(all_subj_df$C, SP)~"SP",
str_detect(all_subj_df$C, ELD)~"ELD",
str_detect(all_subj_df$C, PI)~"PI",
str_detect(all_subj_df$C, VI)~"VI"
)
all_subj_df$C[is.na(all_subj_df$C)] <- ""
all_subj_df$B[is.na(all_subj_df$B)] <- ""
all_subj_df$D<-paste(all_subj_df$A,all_subj_df$B,all_subj_df$C, sep="+")
all_subj_df<-all_subj_df%>%
mutate(D1=gsub("(\\+)*$", "", D))
# unique(all_subj_df$Activities)
# unique(all_subj_df$D1)
all_subj_df$Activities_QC1<-all_subj_df$D1
all_subj_df <- all_subj_df %>% rename(Ontology_One=A,Ontology_Two=B,Ontology_Three=C)
return(all_subj_df)
}
get_exact_computer_app_usage_time <- function(all_subj_df) {
all_subj_df <- all_subj_df %>%
mutate(Application_QC2=case_when(str_detect(Activities_QC1, computer_usage_pattern)~Application_QC1))
## CHECK FOR DEFAULT VALUE!!!
# View(na.locf(all_subj_df$Application))
# View(all_subj_df$Application)
return(all_subj_df)
}
get_final_app_usage <- function(all_subj_df) {
all_subj_df <- all_subj_df %>%
mutate(Application_QC3=Application_QC2) ## @TANIM - CHANGE HERE!!!
return(all_subj_df)
}
get_final_activities_and_app_usage <- function(all_subj_df) {
## 1. Rafactor and get final activity column
all_subj_df <- get_final_activities(all_subj_df)
## 2. Remove app usage data except C-R & C-W
all_subj_df <- get_exact_computer_app_usage_time(all_subj_df)
## 3. Rafactor and get final app usage column
all_subj_df <- get_final_app_usage(all_subj_df)
return(all_subj_df)
}
format_activity_data <- function() {
all_subj_df <- custom_read_csv(file.path(curated_data_dir, physiological_data_dir, qc0_file_name))
## 1. Get final ontologies column
## 2. Remove app usage data except C-R & C-W
## 3. Get final app usage column
all_subj_df <- get_final_activities_and_app_usage(all_subj_df) %>%
select(Participant_ID,
Day,
Treatment,
Timestamp,
Sinterface_Time,
TreatmentTime,
Raw_PP,
PP,
E4_HR,
E4_EDA,
iWatch_HR,
Activities,
Activities_QC1,
Activities_QC2,
Application,
Application_QC1,
Application_QC2,
Application_QC3,
Ontology_One,
Ontology_Two,
Ontology_Three
)
View(all_subj_df)
convert_to_csv(all_subj_df, file.path(curated_data_dir, physiological_data_dir, qc0_file_name))
convert_to_csv(all_subj_df, file.path(curated_data_dir, physiological_data_dir, qc99_file_name))
}
#-------------------------#
#-------Main Program------#
#-------------------------#
## activity denotes both subjects work activity and app usage activity
format_activity_data()
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(grid)
library(gridExtra)
library(dplyr)
library(ggpubr)
#install.packages('DataCombine')
library(DataCombine)
library(dplyr)
library(reshape2)
library(tidyr)
library(stringr)
library(plyr)
library(ggplot2)
library(dplyr)
library(miceadds)
library(gtools)
library(ggpubr)
library(gvlma)
library(MASS)
library(reshape2)
library(ggcorrplot)
library(GGally)
library(ggnewscale)
library(scales)
current_dir <- getwd()
setwd('..')
root_dir <- getwd()
data_dir <- file.path(root_dir, 'curated-data/physiological-data')
data_file_name<-'qc99_all_subj.csv'
DF<-read.csv(file.path(data_dir,data_file_name),stringsAsFactors = FALSE)
file_name <- 'Quantitive_All_subject.csv'
DF<-DF[!(DF$Participant_ID=="T005" & DF$Day=="Day4"),]
DF$Day[DF$Day=="Day5"] <- "Day4"
Subject_id<-factor(DF$Participant_ID)
Number_of_subjects=nlevels(Subject_id)
for (i in 1:Number_of_subjects) {
DF_T001<-subset(DF, Participant_ID==levels(Subject_id)[i])
Sub_file_name<-paste0(levels(Subject_id)[i],".csv")
convert_to_csv(DF_T001, file.path(root_dir,curated_data_dir, physiological_data_dir, Sub_file_name))
}
convert_to_csv(DF, file.path(root_dir,curated_data_dir, physiological_data_dir, file_name))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(grid)
library(gridExtra)
library(dplyr)
library(ggpubr)
#install.packages('DataCombine')
library(DataCombine)
library(dplyr)
library(reshape2)
library(tidyr)
library(stringr)
library(plyr)
library(ggplot2)
library(dplyr)
library(miceadds)
library(gtools)
library(ggpubr)
library(gvlma)
library(MASS)
library(reshape2)
library(ggcorrplot)
library(GGally)
library(ggnewscale)
library(scales)
current_dir <- getwd()
setwd('..')
root_dir <- getwd()
data_dir <- file.path(root_dir, 'curated-data/physiological-data')
data_file_name<-'Quantitive_All_subject.csv'
DF_PP<-read.csv(file.path(data_dir,data_file_name),stringsAsFactors = FALSE)
BaseLine<-function(fun.data, fun.x, fun.y, session, name, y_max, Day){
t<-ggplot(data = fun.data) +
geom_line(aes(x = fun.x, y = fun.y, colour = interaction(session, Day), group = interaction(session, Day)))+
theme_bw()+
theme(plot.margin=unit(c(1,1,1,1),"cm"),plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
labs(title=name ,fun.data, x="Time", y=bquote(paste('Perinasal Perspiration [',''^'o','C',''^2,']')))+
theme(legend.position = "bottom")+theme(legend.title = element_blank())+
ylim(0.0015, 0.008)+
scale_color_manual(labels = c("Day1", "Day2","Day3", "Day4"), values = c("RB.Day1"="orange", "RB.Day2"="red", "RB.Day3"="green", "RB.Day4"="blue"))
return(t)
}
WorkingSession<-function(fun.data, fun.x, fun.y, session, name, y_max, Day){
t<-ggplot(data = fun.data) +
geom_line(aes(x = fun.x, y = fun.y, colour = interaction(session, Day), group = interaction(session, Day)))+
theme_bw()+
theme(plot.margin=unit(c(1,1,1,1),"cm"),plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
labs(title=name ,fun.data, x="Time", y=bquote(paste('Perinasal Perspiration [',''^'o','C',''^2,']')))+
theme(legend.position = "bottom")+theme(legend.title = element_blank())+
#scale_color_manual(values = cols)+
ylim(0.0025, 0.007)+
scale_color_manual(labels = c("Day1",
"Day2",
"Day3",
"Day4"),
values = c("WS.Day1"="orange",
"WS.Day2"="red",
"WS.Day3"="green",
"WS.Day4"="blue"))
return(t)
}
mean_line<-function(df, name){
plot<-ggplot(df)+
geom_hline(aes(yintercept=df$x[1],linetype="Day1"),size=1, color="orange" )+
geom_hline(aes(yintercept=df$x[2],linetype="Day2"),size=1, color="red" )+
geom_hline(aes(yintercept=df$x[3],linetype="Day3"),size=1, color="green" )+
geom_hline(aes(yintercept=df$x[4],linetype="Day4"),size=1, color="blue" )+
scale_linetype_manual(name = "",values = c(2, 2,2,2),guide = guide_legend(override.aes = list(color = c("orange", "red", "green", "blue"))))+theme_bw()+
theme(text = element_text(size=12 ,color = "black"),legend.position = "bottom")+theme(legend.title = element_blank())+
labs(title=name, y=bquote(paste('Mean Perinasal Perspiration [',''^'o','C',''^2,']')))+
theme(plot.title = element_text(hjust = 0.5))
return (plot)
}
mean_of_session<-function(DataFrame){
DataFrame<-DataFrame %>% filter(PP != 'NA')
mean_session<-aggregate(DataFrame[,8], list(DataFrame$Day), mean)
return(mean_session)
}
plot_list<-list()
sid<-factor(DF_PP$Participant_ID)
n=nlevels(sid)
# DF_RB<-subset(DF_PP, Participant_ID=="T003" & Treatment=="RB")
# y_max=max(DF_RB$PP)
# figure<-BaseLine(DF_RB, DF_RB$TreatmentTime, DF_RB$PP, DF_RB$Treatment,title_baseline, y_max, DF_RB$Day)
# print(figure)
for (i in 1:n) {
DF_RB<-subset(DF_PP, Participant_ID==levels(sid)[i] & Treatment=="RB")
title_baseline <- paste0(levels(sid)[i], " Baseline")
y_max=max(DF_RB$PP)
figure<-BaseLine(DF_RB, DF_RB$TreatmentTime, DF_RB$PP, DF_RB$Treatment,title_baseline, y_max, DF_RB$Day)
print(figure)
mean_baseline <- mean_of_session(DF_RB)
title="Mean lines of Baseline"
mean_baseline=mean_line(mean_baseline, title)
print(mean_baseline)
DF_WS<-subset(DF_PP, Participant_ID==levels(sid)[i] & Treatment=="WS")
title_ws <- paste0(levels(sid)[i], " WorkingSession")
y_max=max(DF_WS$PP)
figure<-WorkingSession(DF_WS, DF_WS$TreatmentTime, DF_WS$PP, DF_WS$Treatment,title_ws, y_max, DF_WS$Day)
print(figure)
mean_baseline <- mean_of_session(DF_WS)
title="Mean lines of WorkingSession"
mean_baseline=mean_line(mean_baseline, title)
print(mean_baseline)
}
# for (i in 1:n) {
#   DF_WS<-subset(DF_PP, Participant_ID==levels(sid)[i] & Treatment=="WS")
#   title_ws <- paste0(levels(sid)[i], " WorkingSession")
#   y_max=max(DF_WS$PP)
#   figure<-WorkingSession(DF_WS, DF_WS$TreatmentTime, DF_WS$PP, DF_WS$Treatment,title_ws, y_max, DF_WS$Day)
#   print(figure)
#
#   mean_baseline <- mean_of_session(DF_WS)
#   title="Mean lines of WorkingSession"
#   mean_baseline=mean_line(mean_baseline, title)
#   print(mean_baseline)
#
#}
plot_list<-list()
sid<-factor(DF_PP$Participant_ID)
n=nlevels(sid)
# DF_RB<-subset(DF_PP, Participant_ID=="T003" & Treatment=="RB")
# y_max=max(DF_RB$PP)
# figure<-BaseLine(DF_RB, DF_RB$TreatmentTime, DF_RB$PP, DF_RB$Treatment,title_baseline, y_max, DF_RB$Day)
# print(figure)
for (i in 1:n) {
DF_RB<-subset(DF_PP, Participant_ID==levels(sid)[i] & Treatment=="RB")
title_baseline <- paste0(levels(sid)[i], " Baseline")
y_max=max(DF_RB$PP)
figure<-BaseLine(DF_RB, DF_RB$TreatmentTime, DF_RB$PP, DF_RB$Treatment,title_baseline, y_max, DF_RB$Day)
print(figure)
plot_list[[length(plot_list) + 1]] <- figure
mean_baseline <- mean_of_session(DF_RB)
title="Mean lines of Baseline"
mean_baseline=mean_line(mean_baseline, title)
print(mean_baseline)
plot_list[[length(plot_list) + 1]] <- mean_baseline
DF_WS<-subset(DF_PP, Participant_ID==levels(sid)[i] & Treatment=="WS")
title_ws <- paste0(levels(sid)[i], " WorkingSession")
y_max=max(DF_WS$PP)
figure<-WorkingSession(DF_WS, DF_WS$TreatmentTime, DF_WS$PP, DF_WS$Treatment,title_ws, y_max, DF_WS$Day)
print(figure)
plot_list[[length(plot_list) + 1]] <- figure
mean_baseline <- mean_of_session(DF_WS)
title="Mean lines of WorkingSession"
mean_ws=mean_line(mean_baseline, title)
print(mean_ws)
plot_list[[length(plot_list) + 1]] <- mean_ws
}
#ggarrange(plotlist = plot_list, nrow = 2, ncol = 2,heights= c(3,3), align = c("hv"))
ggarrange(plotlist = plot_list, nrow = 2, ncol = 2,heights= c(3,3), align = c("hv"))
